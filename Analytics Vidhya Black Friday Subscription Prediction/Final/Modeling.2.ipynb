{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data preparation at:  2018-04-12 12:49:27.019347\n",
      "Column  NumPurchasesP  contains nans\n",
      "Column  AvgPurchaseP  contains nans\n",
      "Splitting data into test and training sets\n"
     ]
    }
   ],
   "source": [
    "print('Starting data preparation at: ', datetime.datetime.now())\n",
    "train = pd.read_csv('Hold/train2.csv')\n",
    "test = pd.read_csv('Hold/test2.csv')\n",
    "\n",
    "# Saves product and customer pair for submissions later\n",
    "UP = test.iloc[:, :2]\n",
    "\n",
    "# Saves target variable\n",
    "y = train.Purchase\n",
    "\n",
    "# Drops redundant columns\n",
    "train_ = train.drop(['Purchase', 'City_Category', 'User_ID', 'Product_ID', 'High'], axis=1)\n",
    "test_ = test.drop(['City_Category', 'User_ID', 'Product_ID'], axis=1)\n",
    "\n",
    "# Searches for columns with nulls\n",
    "for col in test_.columns:\n",
    "    if sum(test_[col].isnull()) > 1:\n",
    "        print('Column ', col, ' contains nans')\n",
    "        \n",
    "        # Imputes the average for the column found to contain nulls i.e. std Product\n",
    "        test_[col].fillna((test_[col].mean()), inplace=True)\n",
    "        \n",
    "        \n",
    "# Train test split        \n",
    "print('Splitting data into test and training sets')\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_, y, test_size = .3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge model substantiated and fitted at:  2018-04-12 12:49:39.308805\n",
      "Traing root mean squared error for ridge model\n",
      "Train RMSE: 2473.331373581323\n",
      "Test RMSE: 2488.449923596339\n"
     ]
    }
   ],
   "source": [
    "# Ridge regression\n",
    "ridge = Ridge()\n",
    "ridge.fit(X_train, y_train)\n",
    "print('Ridge model substantiated and fitted at: ', datetime.datetime.now())\n",
    "\n",
    "print('Traing root mean squared error for ridge model')\n",
    "y_pred_train = ridge.predict(X_train)\n",
    "rmseTrain = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "print(\"Train RMSE: {}\".format(rmseTrain))\n",
    "\n",
    "y_pred = ridge.predict(X_test)\n",
    "rmseTest = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Test RMSE: {}\".format(rmseTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting grid search on Ridge at:  2018-04-12 12:49:41.904868\n",
      "{'alpha': 1}\n",
      "Gridsearch for ridge alpha performed at:  2018-04-12 12:49:47.621140\n",
      "Best alpha is:  {'alpha': 1}\n",
      "Traing root mean squared error for ridge model with optimized alpha\n",
      "Train RMSE: 2473.331373581323\n",
      "Test RMSE: 2488.449923596339\n",
      "Ending grid search on Ridge at:  2018-04-12 12:49:47.752110\n"
     ]
    }
   ],
   "source": [
    "# Grid search on Ridge\n",
    "print('Starting grid search on Ridge at: ', datetime.datetime.now())\n",
    "\n",
    "ridge = Ridge()\n",
    "\n",
    "# Use a grid over parameters of interest\n",
    "param_grid = { \n",
    "           \"alpha\" : [.001, .01, .1, 1, 10, 100, 1000, 1000000]\n",
    "}\n",
    "CV_ridge = GridSearchCV(estimator=ridge, param_grid=param_grid, cv= 3)\n",
    "CV_ridge.fit(X_train, y_train)\n",
    "print (CV_ridge.best_params_)\n",
    "bp = CV_ridge.best_params_\n",
    "\n",
    "print('Gridsearch for ridge alpha performed at: ', datetime.datetime.now())\n",
    "print('Best alpha is: ', CV_ridge.best_params_)\n",
    "\n",
    "ridge = Ridge(alpha=bp['alpha'])\n",
    "\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "print('Traing root mean squared error for ridge model with optimized alpha')\n",
    "y_pred_train = ridge.predict(X_train)\n",
    "rmseTrain = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "print(\"Train RMSE: {}\".format(rmseTrain))\n",
    "\n",
    "y_pred = ridge.predict(X_test)\n",
    "rmseTest = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Test RMSE: {}\".format(rmseTest))\n",
    "\n",
    "print('Ending grid search on Ridge at: ', datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting grid search on Ridge at:  2018-04-10 18:03:55.259495\n",
      "{'alpha': 0.01}\n",
      "Gridsearch for ridge alpha performed at:  2018-04-10 18:04:01.664906\n",
      "Best alpha is:  {'alpha': 0.01}\n",
      "Traing root mean squared error for ridge model with optimized alpha\n",
      "Train RMSE: 2473.3313730417294\n",
      "Test RMSE: 2488.4499165353836\n",
      "Ending grid search on Ridge at:  2018-04-10 18:04:01.961527\n"
     ]
    }
   ],
   "source": [
    "# Grid search on Ridge\n",
    "print('Starting grid search on Ridge at: ', datetime.datetime.now())\n",
    "\n",
    "lasso = Lasso()\n",
    "\n",
    "# Use a grid over parameters of interest\n",
    "param_grid = { \n",
    "           \"alpha\" : [.001, .01, .1, 1, 10, 100, 1000, 1000000]\n",
    "}\n",
    "CV_ridge = GridSearchCV(estimator=lasso, param_grid=param_grid, cv= 3)\n",
    "CV_ridge.fit(X_train, y_train)\n",
    "print (CV_ridge.best_params_)\n",
    "bp = CV_ridge.best_params_\n",
    "\n",
    "print('Gridsearch for ridge alpha performed at: ', datetime.datetime.now())\n",
    "print('Best alpha is: ', CV_ridge.best_params_)\n",
    "\n",
    "lasso = Lasso(alpha=bp['alpha'])\n",
    "\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "print('Traing root mean squared error for ridge model with optimized alpha')\n",
    "y_pred_train = lasso.predict(X_train)\n",
    "rmseTrain = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "print(\"Train RMSE: {}\".format(rmseTrain))\n",
    "\n",
    "y_pred = lasso.predict(X_test)\n",
    "rmseTest = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Test RMSE: {}\".format(rmseTest))\n",
    "\n",
    "print('Ending grid search on Ridge at: ', datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ridge regression submission\n",
    "y_pred = ridge.predict(test_)\n",
    "y_pred = pd.DataFrame(y_pred)\n",
    "submission = pd.concat([UP, y_pred], axis=1)\n",
    "submission = submission.rename(columns={0: 'Purchase'})\n",
    "submission.to_csv('Output/Ridge.csv')\n",
    "\n",
    "print('Test submission file saved to Ridge.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting random forest model at:  2018-04-10 18:14:43.808584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py:723: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest model substantiated and fitted at:  2018-04-10 18:14:54.523928\n",
      "Root mean squared error for random forest model:\n",
      "Train RMSE: 1090.632973035505\n",
      "Test RMSE: 2599.481600363038\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Regression\n",
    "print('Starting random forest model at: ', datetime.datetime.now())\n",
    "\n",
    "rfr = RandomForestRegressor(n_jobs=-1, oob_score= True, random_state = 0)\n",
    "rfr.fit(X_train, y_train)\n",
    "print('Random forest model substantiated and fitted at: ', datetime.datetime.now())\n",
    "\n",
    "print('Root mean squared error for random forest model:')\n",
    "y_pred_train = rfr.predict(X_train)\n",
    "rmseTrain = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "print(\"Train RMSE: {}\".format(rmseTrain))\n",
    "\n",
    "y_pred = rfr.predict(X_test)\n",
    "rmseTest = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Test RMSE: {}\".format(rmseTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance determined from random forest\n",
      "                       feature  importance\n",
      "14                AvgPurchaseP    0.753632\n",
      "15                   PropHighU    0.069045\n",
      "13                AvgPurchaseU    0.033741\n",
      "12               NumPurchasesP    0.030617\n",
      "11               NumPurchasesU    0.028803\n",
      "2                   Occupation    0.017175\n",
      "6           Product_Category_2    0.013142\n",
      "1                          Age    0.010985\n",
      "3   Stay_In_Current_City_Years    0.010405\n",
      "7           Product_Category_3    0.009527\n",
      "5           Product_Category_1    0.008206\n",
      "4               Marital_Status    0.003725\n",
      "0                       Gender    0.003268\n",
      "9                            A    0.002784\n",
      "8                            C    0.002647\n",
      "10                           B    0.002298\n"
     ]
    }
   ],
   "source": [
    "# Creating feature importance data frame\n",
    "importance = list(rfr.feature_importances_)\n",
    "feature = list(X_train.columns)\n",
    "feature_importance = pd.DataFrame({'feature': feature, 'importance': importance})\n",
    "\n",
    "print('Feature importance determined from random forest')\n",
    "print(feature_importance.sort_values('importance', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating submission for RFR\n",
    "y_pred = rfr.predict(test_)\n",
    "y_pred = pd.DataFrame(y_pred)\n",
    "submission = pd.concat([UP, y_pred], axis=1)\n",
    "submission = submission.rename(columns={0: 'Purchase'})\n",
    "submission.to_csv('Output/RFR.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier substantiated\n",
      "search substantiated\n",
      "Start random fit:  2018-03-29 22:14:27.473362\n",
      "End random fit:  2018-03-29 23:36:12.473457\n",
      "Best Params:  {'n_estimators': 450, 'min_samples_leaf': 25, 'max_features': 'auto', 'max_depth': 20}\n"
     ]
    }
   ],
   "source": [
    "# Running random search on RFR\n",
    "print('Starting random search on RFR at: ', datetime.datetime.now())\n",
    "\n",
    "param_grid = { \n",
    "              \"n_estimators\": np.arange(200, 500, 50),\n",
    "              \"max_features\" : ['auto'],\n",
    "              \"min_samples_leaf\": np.arange(10,30,5),\n",
    "              'max_depth' : np.arange(20, 60, 10)\n",
    "}\n",
    "\n",
    "rfr = RandomForestRegressor(n_jobs=-1, oob_score= True, random_state = 0)\n",
    "print('classifier substantiated')\n",
    "    \n",
    "CV_rfr = RandomizedSearchCV(estimator=rfr, param_distributions=param_grid, cv=3)\n",
    "print('search substantiated')\n",
    "    \n",
    "print(\"Start random fit: \", datetime.datetime.now())\n",
    "CV_rfr.fit(X_train, y_train)\n",
    "print(\"End random fit: \", datetime.datetime.now())\n",
    "\n",
    "print('Best Params: ', CV_rfr.best_params_)\n",
    "bp = CV_rfr.best_params_ # best parameters\n",
    "\n",
    "rfr = RandomForestRegressor(\n",
    "n_estimators = bp['n_estimators'], \n",
    "max_features= bp['max_features'],\n",
    "min_samples_leaf= bp['min_samples_leaf'], \n",
    "max_depth=bp['max_depth'])\n",
    "    \n",
    "print('Classifier with best parameters set')\n",
    "     \n",
    "print(\"Start rfr fit: \", datetime.datetime.now())\n",
    "rfr.fit(X_train, y_train)\n",
    "print(\"End rfr fit: \", datetime.datetime.now())\n",
    "\n",
    "print('RMSE for optimized rfr')\n",
    "y_pred_train = rfr.predict(X_train)\n",
    "rmseTrain = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "print(\"Train RMSE: {}\".format(rmseTrain))\n",
    "\n",
    "y_pred = rfr.predict(X_test)\n",
    "rmseTest = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Test RMSE: {}\".format(rmseTest))\n",
    "\n",
    "print('Ending random search on RFR at: ', datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier with best parameters set\n",
      "Start rfr fit:  2018-04-10 18:20:32.677055\n",
      "End rfr fit:  2018-04-10 18:36:42.647419\n",
      "RMSE for optimized rfr\n",
      "Train RMSE: 2229.8058025971163\n",
      "Test RMSE: 2439.522374395774\n",
      "Ending random search on RFR at:  2018-04-10 18:37:39.082009\n"
     ]
    }
   ],
   "source": [
    "bp = {'n_estimators': 450, 'min_samples_leaf': 25, 'max_features': 'auto', 'max_depth': 20}\n",
    "\n",
    "rfr = RandomForestRegressor(\n",
    "n_estimators = bp['n_estimators'], \n",
    "max_features= bp['max_features'],\n",
    "min_samples_leaf= bp['min_samples_leaf'], \n",
    "max_depth=bp['max_depth'])\n",
    "    \n",
    "print('Classifier with best parameters set')\n",
    "     \n",
    "print(\"Start rfr fit: \", datetime.datetime.now())\n",
    "rfr.fit(X_train, y_train)\n",
    "print(\"End rfr fit: \", datetime.datetime.now())\n",
    "\n",
    "print('RMSE for optimized rfr')\n",
    "y_pred_train = rfr.predict(X_train)\n",
    "rmseTrain = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "print(\"Train RMSE: {}\".format(rmseTrain))\n",
    "\n",
    "y_pred = rfr.predict(X_test)\n",
    "rmseTest = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Test RMSE: {}\".format(rmseTest))\n",
    "\n",
    "print('Ending random search on RFR at: ', datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test submission for RFR saved to RFR2.csv\n"
     ]
    }
   ],
   "source": [
    "# Creating submission for RFR optimized from random search\n",
    "y_pred = rfr.predict(test_)\n",
    "y_pred = pd.DataFrame(y_pred)\n",
    "submission = pd.concat([UP, y_pred], axis=1)\n",
    "submission = submission.rename(columns={0: 'Purchase'})\n",
    "submission.to_csv('RFR2.csv')\n",
    "print('Test submission for RFR saved to RFR2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier substantiated\n",
      "search substantiated\n",
      "Start random fit:  2018-03-30 00:14:08.745511\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-ed69d938b2c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Start random fit: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mCV_rfr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"End random fit: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    326\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 328\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Running grid search on RFR\n",
    "print('Starting grid search on RFR at: ', datetime.datetime.now())\n",
    "\n",
    "param_grid = { \n",
    "              \"n_estimators\": np.arange(200, 500, 20),\n",
    "              \"max_features\" : ['auto'],\n",
    "              \"min_samples_leaf\": np.arange(10,30,2),\n",
    "              'max_depth' : np.arange(20, 60, 5)\n",
    "}\n",
    "\n",
    "rfr = RandomForestRegressor(n_jobs=-1, oob_score= True, random_state = 0)\n",
    "print('classifier substantiated')\n",
    "    \n",
    "CV_rfr = GridSearchCV(estimator=rfr, param_grid=param_grid, cv=3)\n",
    "print('search substantiated')\n",
    "    \n",
    "print(\"Start random fit: \", datetime.datetime.now())\n",
    "CV_rfr.fit(X_train, y_train)\n",
    "print(\"End random fit: \", datetime.datetime.now())\n",
    "\n",
    "print('Best Params: ', CV_rfr.best_params_)\n",
    "bp = CV_rfr.best_params_ # best parameters\n",
    "\n",
    "rfr = RandomForestRegressor(\n",
    "n_estimators = bp['n_estimators'], \n",
    "max_features= bp['max_features'],\n",
    "min_samples_leaf= bp['min_samples_leaf'], \n",
    "max_depth=bp['max_depth'])\n",
    "    \n",
    "print('Classifier with best parameters set')\n",
    "     \n",
    "print(\"Start rfr fit: \", datetime.datetime.now())\n",
    "rfr.fit(X_train, y_train)\n",
    "print(\"End rfr fit: \", datetime.datetime.now())\n",
    "\n",
    "print('RMSE for optimized rfr')\n",
    "y_pred_train = rfr.predict(X_train)\n",
    "rmseTrain = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "print(\"Train RMSE: {}\".format(rmseTrain))\n",
    "f\n",
    "y_pred = rfr.predict(X_test)\n",
    "rmseTest = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Test RMSE: {}\".format(rmseTest))\n",
    "\n",
    "\n",
    "print('Starting grid search on RFR at: ', datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating submission csv for grid search optimized rfr model\n",
    "y_pred = rfr.predict(test_)\n",
    "y_pred = pd.DataFrame(y_pred)\n",
    "submission = pd.concat([UP, y_pred], axis=1)\n",
    "submission = submission.rename(columns={0: 'Purchase'})\n",
    "submission.to_csv('Output/RFR3.csv')\n",
    "print('Test submission for RFR saved to RFR3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting MLPR build at:  2018-04-10 20:17:55.069664\n",
      "mlpr model substantiated and fitted at:  2018-04-10 20:21:59.215550\n",
      "RMSE for MLPR model: \n",
      "Train RMSE: 2467.6250463142665\n",
      "Test RMSE: 2484.1670203047875\n"
     ]
    }
   ],
   "source": [
    "# MLPR \n",
    "print('Starting MLPR build at: ', datetime.datetime.now())\n",
    "mlp = MLPRegressor(random_state = 0) \n",
    "mlp.fit(X_train, y_train)\n",
    "print('mlpr model substantiated and fitted at: ', datetime.datetime.now())\n",
    "\n",
    "print('RMSE for MLPR model: ')\n",
    "y_pred_train = mlp.predict(X_train)\n",
    "rmseTrain = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "print(\"Train RMSE: {}\".format(rmseTrain))\n",
    "\n",
    "y_pred = mlp.predict(X_test)\n",
    "rmseTest = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Test RMSE: {}\".format(rmseTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating submission csv for MLPR\n",
    "y_pred_submission = mlp.predict(test_)\n",
    "y_pred_DF = pd.DataFrame(y_pred_submission)\n",
    "submission = pd.concat([UP, y_pred_DF], axis=1)\n",
    "submission = submission.rename(columns={0: 'Purchase'})\n",
    "submission.to_csv('Output/MLPR1.csv')\n",
    "print('Sumbission for MLPR model saved to MLPR1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting MLPR random search at:  2018-04-10 23:22:27.061922\n",
      "data fitted\n",
      "{'max_iter': 1750, 'hidden_layer_sizes': 3, 'batch_size': 10, 'alpha': 0.0001}\n",
      "regressor substantiated with best params\n",
      "data fitted with best params\n",
      "RMSE for optimized mlpr\n",
      "Train RMSE: 2473.719212829708\n",
      "Test RMSE: 2489.7192562620767\n",
      "Ending MLPR random search at:  2018-04-11 03:38:28.556120\n"
     ]
    }
   ],
   "source": [
    "# Running random search on MLPR\n",
    "print('Starting MLPR random search at: ', datetime.datetime.now())\n",
    "\n",
    "param_grid = { \n",
    "    \"hidden_layer_sizes\" : [1 ,2, 3],\n",
    "    \"alpha\" : [.0001, .001, .01],\n",
    "    \"batch_size\" : [1, 10, 50, 100, 250],\n",
    "    \"max_iter\"  : np.arange(1250, 2250, 250)\n",
    "            }\n",
    "\n",
    "mlp = MLPRegressor(random_state = 0) \n",
    "\n",
    "rs_mlp = RandomizedSearchCV(estimator=mlp, param_distributions=param_grid, cv= 3)\n",
    "\n",
    "rs_mlp.fit(X_train, y_train)\n",
    "print('data fitted')\n",
    "    \n",
    "bp = rs_mlp.best_params_ # best parameters\n",
    "print(rs_mlp.best_params_)\n",
    "\n",
    "    \n",
    "mlp = MLPRegressor(random_state=0, hidden_layer_sizes = bp['hidden_layer_sizes'], \n",
    "alpha=bp['alpha'],\n",
    "batch_size=bp['batch_size'], \n",
    "max_iter=bp['max_iter'])\n",
    "\n",
    "print('regressor substantiated with best params')\n",
    "    \n",
    "mlp.fit(X_train, y_train)\n",
    "print('data fitted with best params')\n",
    "\n",
    "print('RMSE for optimized mlpr')\n",
    "y_pred_train = mlp.predict(X_train)\n",
    "rmseTrain = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "print(\"Train RMSE: {}\".format(rmseTrain))\n",
    "\n",
    "y_pred = mlp.predict(X_test)\n",
    "rmseTest = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Test RMSE: {}\".format(rmseTest))\n",
    "\n",
    "print('Ending MLPR random search at: ', datetime.datetime.now())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regressor substantiated with best params\n",
      "data fitted with best params\n",
      "RMSE for optimized mlpr\n",
      "Train RMSE: 2483.3996341888383\n",
      "Test RMSE: 2499.4141435559336\n",
      "Ending MLPR random search at:  2018-04-10 22:00:23.515630\n"
     ]
    }
   ],
   "source": [
    "bp = {'max_iter': 1250, 'hidden_layer_sizes': 2, 'batch_size': 1, 'alpha': 0.001}\n",
    "\n",
    "mlp = MLPRegressor(random_state=0, hidden_layer_sizes = bp['hidden_layer_sizes'], \n",
    "alpha=bp['alpha'],\n",
    "batch_size=bp['batch_size'], \n",
    "max_iter=bp['max_iter'])\n",
    "\n",
    "print('regressor substantiated with best params')\n",
    "    \n",
    "mlp.fit(X_train, y_train)\n",
    "print('data fitted with best params')\n",
    "\n",
    "print('RMSE for optimized mlpr')\n",
    "y_pred_train = mlp.predict(X_train)\n",
    "rmseTrain = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "print(\"Train RMSE: {}\".format(rmseTrain))\n",
    "\n",
    "y_pred = mlp.predict(X_test)\n",
    "rmseTest = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Test RMSE: {}\".format(rmseTest))\n",
    "\n",
    "print('Ending MLPR random search at: ', datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating submission csv for random search optimized MLPR\n",
    "y_pred_submission = mlp.predict(test_)\n",
    "y_pred_DF = pd.DataFrame(y_pred_submission)\n",
    "submission = pd.concat([UP, y_pred_DF], axis=1)\n",
    "submission = submission.rename(columns={0: 'Purchase'})\n",
    "submission.to_csv('Output/MLPR2.csv')\n",
    "print('Sumbission for xgr model saved to MLPR2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting GBR model building at:  2018-04-10 20:22:01.316848\n",
      "regressor substaintiated\n",
      "data fitted\n",
      "RMSE for optimized mlpr\n",
      "Train RMSE: 2432.4198217573903\n",
      "Test RMSE: 2453.141669366565\n",
      "Ending GBR random search at:  2018-04-10 20:22:44.575913\n"
     ]
    }
   ],
   "source": [
    "# GBR\n",
    "print('Starting GBR model building at: ', datetime.datetime.now())\n",
    "\n",
    "gbr = GradientBoostingRegressor(random_state =0)\n",
    "print('regressor substaintiated')\n",
    "\n",
    "gbr.fit(X_train, y_train)\n",
    "print('data fitted')\n",
    "\n",
    "print('RMSE for optimized mlpr')\n",
    "y_pred_train = gbr.predict(X_train)\n",
    "rmseTrain = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "print(\"Train RMSE: {}\".format(rmseTrain))\n",
    "\n",
    "y_pred = gbr.predict(X_test)\n",
    "rmseTest = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Test RMSE: {}\".format(rmseTest))\n",
    "\n",
    "print('Ending GBR random search at: ', datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating submission csv for GBR\n",
    "y_pred_submission = gbr.predict(test_)\n",
    "y_pred_DF = pd.DataFrame(y_pred_submission)\n",
    "submission = pd.concat([UP, y_pred_DF], axis=1)\n",
    "submission = submission.rename(columns={0: 'Purchase'})\n",
    "submission.to_csv('Output/GBR1.csv')\n",
    "print('Sumbission for gbr model saved to GBR1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting GBR random search at:  2018-04-11 03:38:28.587874\n",
      "regressor substaintiated\n",
      "search substantiated\n",
      "data fitted\n",
      "{'min_samples_leaf': 15, 'max_features': 8, 'max_depth': 12, 'learning_rate': 0.05}\n",
      "regressor substantiated with best params\n",
      "data fitted with best params\n",
      "RMSE for optimized mlpr\n",
      "Train RMSE: 2153.181622905302\n",
      "Test RMSE: 2422.9038270298124\n",
      "Ending GBR random search at:  2018-04-11 05:52:57.668978\n"
     ]
    }
   ],
   "source": [
    "# Running random search on GBR\n",
    "print('Starting GBR random search at: ', datetime.datetime.now())\n",
    "\n",
    "param_grid = {'learning_rate':  [.01, .05, 0.15, 0.3, 0.5],\n",
    "              'max_depth': [8, 9, 10, 11, 12],\n",
    "              'min_samples_leaf': [ 15, 18, 21, 24],\n",
    "              'max_features': np.arange(2, 17, 3)\n",
    "              }  \n",
    "\n",
    "gbr = GradientBoostingRegressor(random_state =0)\n",
    "print('regressor substaintiated')\n",
    "\n",
    "CV_gbr = RandomizedSearchCV(estimator=gbr, param_distributions=param_grid, cv=3)\n",
    "print('search substantiated')\n",
    "\n",
    "CV_gbr.fit(X_train, y_train)\n",
    "print('data fitted')\n",
    "    \n",
    "bp = CV_gbr.best_params_ # best parameters\n",
    "print(CV_gbr.best_params_)\n",
    "\n",
    "bp = CV_gbr.best_params_ # best parameters\n",
    "    \n",
    "gbr = GradientBoostingRegressor(learning_rate = bp['learning_rate'], \n",
    "    max_features=bp['max_features'],\n",
    "    min_samples_leaf=bp['min_samples_leaf'], \n",
    "    max_depth=bp['max_depth'])\n",
    "    \n",
    "print('regressor substantiated with best params')\n",
    "    \n",
    "gbr.fit(X_train, y_train)\n",
    "print('data fitted with best params') \n",
    "\n",
    "print('RMSE for optimized mlpr')\n",
    "y_pred_train = gbr.predict(X_train)\n",
    "rmseTrain = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "print(\"Train RMSE: {}\".format(rmseTrain))\n",
    "\n",
    "y_pred = gbr.predict(X_test)\n",
    "rmseTest = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Test RMSE: {}\".format(rmseTest))\n",
    "\n",
    "print('Ending GBR random search at: ', datetime.datetime.now())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sumbission for gbr model saved to GBR2.csv\n"
     ]
    }
   ],
   "source": [
    "# Creating random search optimized submission csv for GBR\n",
    "y_pred_submission = gbr.predict(test_)\n",
    "y_pred_DF = pd.DataFrame(y_pred_submission)\n",
    "submission = pd.concat([UP, y_pred_DF], axis=1)\n",
    "submission = submission.rename(columns={0: 'Purchase'})\n",
    "submission.to_csv('Output/GBR411.csv')\n",
    "print('Sumbission for gbr model saved to GBR2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Running grid search on GBR\n",
    "print('Starting GBR grid search at: ', datetime.datetime.now())\n",
    "\n",
    "param_grid = {'learning_rate':  [.01, .05, 0.15, 0.3, 0.5],\n",
    "              'max_depth': [8, 9, 10, 11, 12],\n",
    "              'min_samples_leaf': [ 15, 18, 21, 24],\n",
    "              'max_features': np.arange(25, 50, 5)\n",
    "              }  \n",
    "\n",
    "gbr = GradientBoostingRegressor(random_state =0)\n",
    "print('regressor substaintiated')\n",
    "\n",
    "CV_gbr = GridSearchCV(estimator=gbr, param_grid=param_grid, cv=3)\n",
    "print('search substantiated')\n",
    "\n",
    "CV_gbr.fit(X_train, y_train)\n",
    "print('data fitted')\n",
    "    \n",
    "bp = CV_gbr.best_params_ # best parameters\n",
    "print(CV_gbr.best_params_)\n",
    "\n",
    "bp = CV_gbr.best_params_ # best parameters\n",
    "    \n",
    "gbr = GradientBoostingRegressor(learning_rate = bp['learning_rate'], \n",
    "    max_features=bp['max_features'],\n",
    "    min_samples_leaf=bp['min_samples_leaf'], \n",
    "    max_depth=bp['max_depth'])\n",
    "    print('regressor substantiated with best params')\n",
    "    \n",
    "gbr.fit(X_train, y_train)\n",
    "print('data fitted with best params') \n",
    "\n",
    "print('RMSE for optimized mlpr')\n",
    "y_pred_train = gbr.predict(X_train)\n",
    "rmseTrain = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "print(\"Train RMSE: {}\".format(rmseTrain))\n",
    "\n",
    "y_pred = gbr.predict(X_test)\n",
    "rmseTest = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Test RMSE: {}\".format(rmseTest))\n",
    "\n",
    "print('Ending GBR random search at: ', datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating submission csv for grid search optimized gbr model\n",
    "y_pred_submission = gbr.predict(test_)\n",
    "y_pred_DF = pd.DataFrame(y_pred_submission)\n",
    "submission = pd.concat([UP, y_pred_DF], axis=1)\n",
    "submission = submission.rename(columns={0: 'Purchase'})\n",
    "submission.to_csv('Output/GBR3.csv')\n",
    "print('Sumbission for gbr model saved to GBR3.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
