{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('Hold/trainDfstats.csv') \n",
    "test = pd.read_csv('Hold/testDfstats.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 550068 entries, 0 to 550067\n",
      "Data columns (total 89 columns):\n",
      "User_ID                       550068 non-null int64\n",
      "Product_ID                    550068 non-null object\n",
      "Gender                        550068 non-null object\n",
      "Age                           550068 non-null object\n",
      "Occupation                    550068 non-null int64\n",
      "City_Category                 550068 non-null object\n",
      "Stay_In_Current_City_Years    550068 non-null object\n",
      "Product_Category_1            550068 non-null int64\n",
      "Product_Category_2            550068 non-null int64\n",
      "Product_Category_3            550068 non-null int64\n",
      "Purchase_Amount               550068 non-null int64\n",
      "Marital_Status                550068 non-null int64\n",
      "Female                        550068 non-null float64\n",
      "Male                          550068 non-null float64\n",
      "Age_0-17                      550068 non-null float64\n",
      "Age_18-25                     550068 non-null float64\n",
      "Age_26-35                     550068 non-null float64\n",
      "Age_36-45                     550068 non-null float64\n",
      "Age_46-50                     550068 non-null float64\n",
      "Age_51-55                     550068 non-null float64\n",
      "Age_55+                       550068 non-null float64\n",
      "0_Occupation                  550068 non-null float64\n",
      "1_Occupation                  550068 non-null float64\n",
      "2_Occupation                  550068 non-null float64\n",
      "3_Occupation                  550068 non-null float64\n",
      "4_Occupation                  550068 non-null float64\n",
      "5_Occupation                  550068 non-null float64\n",
      "6_Occupation                  550068 non-null float64\n",
      "7_Occupation                  550068 non-null float64\n",
      "8_Occupation                  550068 non-null float64\n",
      "9_Occupation                  550068 non-null float64\n",
      "10_Occupation                 550068 non-null float64\n",
      "11_Occupation                 550068 non-null float64\n",
      "12_Occupation                 550068 non-null float64\n",
      "13_Occupation                 550068 non-null float64\n",
      "14_Occupation                 550068 non-null float64\n",
      "15_Occupation                 550068 non-null float64\n",
      "16_Occupation                 550068 non-null float64\n",
      "17_Occupation                 550068 non-null float64\n",
      "18_Occupation                 550068 non-null float64\n",
      "19_Occupation                 550068 non-null float64\n",
      "20_Occupation                 550068 non-null float64\n",
      "City_Category_A               550068 non-null float64\n",
      "City_Category_B               550068 non-null float64\n",
      "City_Category_C               550068 non-null float64\n",
      "Stay_0yr                      550068 non-null float64\n",
      "Stay_1yr                      550068 non-null float64\n",
      "Stay_2yr                      550068 non-null float64\n",
      "Stay_3yr                      550068 non-null float64\n",
      "Stay4+yr                      550068 non-null float64\n",
      "1_Product_Category            550068 non-null float64\n",
      "2_Product_Category            550068 non-null float64\n",
      "3_Product_Category            550068 non-null float64\n",
      "4_Product_Category            550068 non-null float64\n",
      "5_Product_Category            550068 non-null float64\n",
      "6_Product_Category            550068 non-null float64\n",
      "7_Product_Category            550068 non-null float64\n",
      "8_Product_Category            550068 non-null float64\n",
      "9_Product_Category            550068 non-null float64\n",
      "10_Product_Category           550068 non-null float64\n",
      "11_Product_Category           550068 non-null float64\n",
      "12_Product_Category           550068 non-null float64\n",
      "13_Product_Category           550068 non-null float64\n",
      "14_Product_Category           550068 non-null float64\n",
      "15_Product_Category           550068 non-null float64\n",
      "16_Product_Category           550068 non-null float64\n",
      "17_Product_Category           550068 non-null float64\n",
      "18_Product_Category           550068 non-null float64\n",
      "19_Product_Category           550068 non-null float64\n",
      "20_Product_Category           550068 non-null float64\n",
      "AgeNew_0-17_55+               550068 non-null float64\n",
      "AgeNew_26-35                  550068 non-null float64\n",
      "AgeNew_18-25_36_45            550068 non-null float64\n",
      "AgeNew_51+                    550068 non-null float64\n",
      "OccupationNew_0-2             550068 non-null float64\n",
      "OccupationNew_3-5             550068 non-null float64\n",
      "OccupationNew_6-8             550068 non-null float64\n",
      "OccupationNew_9-11            550068 non-null float64\n",
      "OccupationNew_12-14           550068 non-null float64\n",
      "OccupationNew_15-17           550068 non-null float64\n",
      "OccupationNew_18-20           550068 non-null float64\n",
      "Unqiue_Cat_Count              550068 non-null int64\n",
      "2-3_Cat_Count                 550068 non-null int64\n",
      "4-5_Cat_Count                 550068 non-null int64\n",
      "AvgPurchaseAmount             550068 non-null float64\n",
      "NumberPurchasesUser           550068 non-null int64\n",
      "Max_Purchase                  550068 non-null int64\n",
      "Min_Purchase                  550068 non-null int64\n",
      "Standard_Deviation            550068 non-null float64\n",
      "dtypes: float64(71), int64(13), object(5)\n",
      "memory usage: 373.5+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Move columns marital status, female, and male to just before binned age and occupation data\n",
    "# in order to more easily divide data into data frames for testing\n",
    "cols = list(train)\n",
    "cols.insert(69, cols.pop(cols.index('Marital_Status')))\n",
    "cols.insert(69, cols.pop(cols.index('Female')))\n",
    "cols.insert(69, cols.pop(cols.index('Male')))\n",
    "trainDf = train.loc[:, cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainDf['Id'] = trainDf['User_ID'].astype(str)+'_'+ trainDf['Product_ID'].astype(str) \n",
    "test['Id'] = test['User_ID'].astype(str)+'_'+ test['Product_ID'].astype(str) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creates x and y containing all the custom binned data and all features\n",
    "yAll = trainDf.iloc[:,10]\n",
    "xAll = trainDf.iloc[:,11:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Converts all categorical data into type int\n",
    "xAll.iloc[:, :70] = xAll.iloc[:, :70].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:13: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "# Normalizes numeric columns of xAll and creates new dataframe called xAllNorm and yAllNorm\n",
    "xAllT = xAll.iloc[:, 70:]\n",
    "\n",
    "cols = [np.arange(70,78)]\n",
    "\n",
    "xAllNt = xAll.drop(xAll.columns[cols], axis=1)\n",
    "\n",
    "holdNorm = {}\n",
    "for column in xAllT:\n",
    "    \n",
    "    if column == 'Id':\n",
    "        temp = xAllT[column]\n",
    "        temp = temp.reshape(-1, 1)       \n",
    "        holdNorm[column] = xAllT[column]\n",
    "        break\n",
    "        \n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    temp = xAllT[column].as_matrix()\n",
    "    temp = temp.reshape(-1,1)\n",
    "    temp = scaler.fit_transform(temp)\n",
    "    \n",
    "    y = temp.flatten()\n",
    "    holdNorm[column] = y\n",
    "\n",
    "trainNormDf = pd.DataFrame(holdNorm)\n",
    "xAllNorm = pd.merge(xAllNt, trainNormDf, on='Id', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Converts all categorical data into type int\n",
    "yAllNorm = yAll\n",
    "xAllNorm.iloc[:, :70] = xAllNorm.iloc[:, :70].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creates a dataframe that only has original binning of data by dropping custom bins but maintains \n",
    "# normalized numeric features\n",
    "cols = xAllNorm.iloc[:, 59:70]\n",
    "xNbNorm = xAllNorm.drop(cols, axis=1)\n",
    "yNbNorm = yAllNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creates a dataframe that only has original binning of data by dropping custom bins and does not \n",
    "# have normalized numeric features\n",
    "cols = xAll.iloc[:, 59:70]\n",
    "xNb = xAll.drop(cols, axis=1)\n",
    "yNb = yAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Converts all categorical data into type int\n",
    "xNb.iloc[:, :59] = xNb.iloc[:, :59].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xs = [xAll, xAllNorm, xNb, xNbNorm]\n",
    "ys = [yAll, yAllNorm, yNb, yNbNorm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# Removes Id column for all data frames\n",
    "i = 1\n",
    "for df in xs: \n",
    "    print(i)\n",
    "    df.drop('Id',axis=1, inplace=True)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepares test dataframes \n",
    "xAllT = test.iloc[:, 10:]\n",
    "xAllT = xAllT[xAll.columns]\n",
    "\n",
    "xAllNormT = test.iloc[:, 10:]\n",
    "xAllNormT = xAllNormT[xAllNorm.columns]\n",
    "\n",
    "xNbNormT =  test.iloc[:, 10:]\n",
    "xNbNormT = xNbNormT[xNbNorm.columns]\n",
    "\n",
    "xNbT = test.iloc[:, 10:]\n",
    "xNbT = xNbT[xNb.columns]\n",
    "\n",
    "# Creates user product pair data frame for final submissions\n",
    "UserProductPairs = test.iloc[:, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testDfs = [xAllT, xAllNormT, xNbNormT, xNbT]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for data set: 1\n",
      "Train RMSE: 4748.60446747989\n",
      "Test RMSE: 4764.6878065073415\n",
      "\n",
      "Score for data set: 2\n",
      "Train RMSE: 4748.637455865274\n",
      "Test RMSE: 4764.693623573989\n",
      "\n",
      "Score for data set: 3\n",
      "Train RMSE: 4748.6044674798895\n",
      "Test RMSE: 4764.6878065073415\n",
      "\n",
      "Score for data set: 4\n",
      "Train RMSE: 4748.619427370744\n",
      "Test RMSE: 4764.675856257603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression\n",
    "i = 1\n",
    "for v in zip(xs, ys):\n",
    "    x_, y_ = v\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_, y_, test_size = .3, random_state=42)\n",
    "    reg = LinearRegression()\n",
    "    print('Score for data set:', i)\n",
    "   \n",
    "    reg.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_train = reg.predict(X_train)\n",
    "    rmseTrain = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "    print(\"Train RMSE: {}\".format(rmseTrain))\n",
    "\n",
    "    y_pred = reg.predict(X_test)\n",
    "    rmseTest = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    print(\"Test RMSE: {}\\n\".format(rmseTest))\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for data set: 1\n",
      "Train RMSE: 4750.387524741042\n",
      "Test RMSE: 4766.053731015421\n",
      "\n",
      "Score for data set: 2\n",
      "Train RMSE: 4750.387524741986\n",
      "Test RMSE: 4766.053731016517\n",
      "\n",
      "Score for data set: 3\n",
      "Train RMSE: 4750.387524741042\n",
      "Test RMSE: 4766.053731015421\n",
      "\n",
      "Score for data set: 4\n",
      "Train RMSE: 4750.387524741986\n",
      "Test RMSE: 4766.053731016517\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lasso regression\n",
    "i = 1\n",
    "for v in zip(xs, ys):\n",
    "    x_, y_ = v\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_, y_, test_size = .3, random_state=42)\n",
    "    lasso = Lasso(alpha=.1, normalize=True)\n",
    "    print('Score for data set:', i)\n",
    "\n",
    "    lasso.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_train = lasso.predict(X_train)\n",
    "    rmseTrain = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "    print(\"Train RMSE: {}\".format(rmseTrain))\n",
    "\n",
    "    y_pred = lasso.predict(X_test)\n",
    "    rmseTest = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    print(\"Test RMSE: {}\\n\".format(rmseTest))\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha and Score for data set: 1\n",
      "Best Alpha:  {'alpha': 0.01}\n",
      "Train RMSE: 4748.7724623315635\n",
      "Test RMSE: 4764.677345803293\n",
      "\n",
      "Alpha and Score for data set: 2\n",
      "Best Alpha:  {'alpha': 0.01}\n",
      "Train RMSE: 4748.772218169853\n",
      "Test RMSE: 4764.67678503121\n",
      "\n",
      "Alpha and Score for data set: 3\n",
      "Best Alpha:  {'alpha': 0.01}\n",
      "Train RMSE: 4748.77158354285\n",
      "Test RMSE: 4764.656496697765\n",
      "\n",
      "Alpha and Score for data set: 4\n",
      "Best Alpha:  {'alpha': 0.01}\n",
      "Train RMSE: 4748.771580407851\n",
      "Test RMSE: 4764.656480147773\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Gridsearch on lasso regression\n",
    "param_grid = { \"alpha\" : [.001, .01, .1, 1, 10, 100, 100]}\n",
    "\n",
    "i = 1\n",
    "\n",
    "for v in zip(xs, ys):\n",
    "    x_, y_ = v\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_, y_, test_size = .3, random_state=42)\n",
    "    lasso = Lasso(normalize=True)\n",
    "    CV_lasso = GridSearchCV(estimator=lasso, param_grid=param_grid, cv=3)\n",
    "    CV_lasso.fit(X_train, y_train)\n",
    "    print('Alpha and Score for data set:', i)\n",
    "\n",
    "    print('Best Alpha: ', CV_lasso.best_params_)\n",
    "    bestParams = CV_lasso.best_params_\n",
    "\n",
    "    lasso = Lasso(alpha = bestParams['alpha'], normalize=True)\n",
    "\n",
    "    lasso.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_train = lasso.predict(X_train)\n",
    "    rmseTrain = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "    print(\"Train RMSE: {}\".format(rmseTrain))\n",
    "\n",
    "    y_pred = lasso.predict(X_test)\n",
    "    rmseTest = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    print(\"Test RMSE: {}\\n\".format(rmseTest))\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for data set: 1\n",
      "Train RMSE: 4748.604467496582\n",
      "Test RMSE: 4764.687773711606\n",
      "\n",
      "Score for data set: 2\n",
      "Train RMSE: 4748.604467499664\n",
      "Test RMSE: 4764.687745170561\n",
      "\n",
      "Score for data set: 3\n",
      "Train RMSE: 4748.60446750153\n",
      "Test RMSE: 4764.68778365335\n",
      "\n",
      "Score for data set: 4\n",
      "Train RMSE: 4748.604467504582\n",
      "Test RMSE: 4764.687755112295\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ridge regression\n",
    "i = 1\n",
    "for v in zip(xs, ys):\n",
    "    x_, y_ = v\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_, y_, test_size = .3, random_state=42)\n",
    "    ridge = Ridge()\n",
    "    print('Score for data set:', i)\n",
    "    \n",
    "    ridge.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_train = ridge.predict(X_train)\n",
    "    rmseTrain = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "    print(\"Train RMSE: {}\".format(rmseTrain))\n",
    "\n",
    "    y_pred = ridge.predict(X_test)\n",
    "    rmseTest = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    print(\"Test RMSE: {}\\n\".format(rmseTest))\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha and Score for data set: 1\n",
      "Best Alpha:  {'alpha': 0.001}\n",
      "Train RMSE: 4748.6049289849625\n",
      "Test RMSE: 4764.677292508301\n",
      "\n",
      "Alpha and Score for data set: 2\n",
      "Best Alpha:  {'alpha': 0.001}\n",
      "Train RMSE: 4748.604928984963\n",
      "Test RMSE: 4764.677292508301\n",
      "\n",
      "Alpha and Score for data set: 3\n",
      "Best Alpha:  {'alpha': 0.001}\n",
      "Train RMSE: 4748.604929295501\n",
      "Test RMSE: 4764.677352198836\n",
      "\n",
      "Alpha and Score for data set: 4\n",
      "Best Alpha:  {'alpha': 0.001}\n",
      "Train RMSE: 4748.604929295501\n",
      "Test RMSE: 4764.677352198836\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Gridsearch on Ridge regression\n",
    "\n",
    "param_grid = { \"alpha\" : [.001, .01, .1, 1, 10, 100, 100]}\n",
    "\n",
    "i = 1\n",
    "\n",
    "for v in zip(xs, ys):\n",
    "    x_, y_ = v\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_, y_, test_size = .3, random_state=42)\n",
    "    ridge = Ridge(normalize=True)\n",
    "    CV_ridge = GridSearchCV(estimator=ridge, param_grid=param_grid, cv=3)\n",
    "    CV_ridge.fit(X_train, y_train)\n",
    "    print('Alpha and Score for data set:', i)\n",
    "\n",
    "    print('Best Alpha: ', CV_ridge.best_params_)\n",
    "    bestParams = CV_ridge.best_params_\n",
    "\n",
    "    ridge = Ridge(alpha = bestParams['alpha'], normalize=True)\n",
    "\n",
    "    ridge.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_train = ridge.predict(X_train)\n",
    "    rmseTrain = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "    print(\"Train RMSE: {}\".format(rmseTrain))\n",
    "\n",
    "    y_pred = ridge.predict(X_test)\n",
    "    rmseTest = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    print(\"Test RMSE: {}\\n\".format(rmseTest))\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting random forest at:  2018-04-08 19:51:44.135553\n",
      "Score for data set: 1\n",
      "Train RMSE: 2745.245911027414\n",
      "Test RMSE: 5362.268017925762\n",
      "\n",
      "Score for data set: 2\n",
      "Train RMSE: 2746.4819968203237\n",
      "Test RMSE: 5359.525334597407\n",
      "\n",
      "Score for data set: 3\n",
      "Train RMSE: 2746.076319999519\n",
      "Test RMSE: 5349.703086148489\n",
      "\n",
      "Score for data set: 4\n",
      "Train RMSE: 2745.198970816921\n",
      "Test RMSE: 5352.319362701004\n",
      "\n",
      "Ending random forest at:  2018-04-08 19:57:31.557924\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Regression\n",
    "print('Starting random forest at: ', datetime.datetime.now())\n",
    "i = 1\n",
    "for v in zip(xs, ys):\n",
    "    x_, y_ = v\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_, y_, test_size = .3, random_state=42)\n",
    "    rfr = RandomForestRegressor(random_state =0)\n",
    "    print('Score for data set:', i)\n",
    "   \n",
    "    rfr.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_train = rfr.predict(X_train)\n",
    "    rmseTrain = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "    print(\"Train RMSE: {}\".format(rmseTrain))\n",
    "\n",
    "    y_pred = rfr.predict(X_test)\n",
    "    rmseTest = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    print(\"Test RMSE: {}\\n\".format(rmseTest))\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "print('Ending random forest at: ', datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting at:  2018-04-09 13:33:49.394954\n",
      "Best Params:  {'n_estimators': 450, 'min_samples_leaf': 25, 'max_features': 'auto', 'max_depth': 40}\n",
      "Train RMSE: 4484.802015812168\n",
      "Test RMSE: 4805.6168842159195\n",
      "\n",
      "Ending at:  2018-04-09 16:52:42.985290\n"
     ]
    }
   ],
   "source": [
    "# Random search on random forest regression\n",
    "# Saves best parameters in dictionary \n",
    "print('Starting at: ', datetime.datetime.now())\n",
    "\n",
    "param_grid = { \n",
    "              \"n_estimators\": np.arange(200, 500, 50),\n",
    "              \"max_features\" : ['auto'],\n",
    "              \"min_samples_leaf\": np.arange(10,30,5),\n",
    "              'max_depth' : np.arange(20, 60, 10)\n",
    "}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(xs[2], ys[2], test_size = .3, random_state=42)\n",
    "rfr = RandomForestRegressor(n_jobs=-1, oob_score= True, random_state = 0)\n",
    "CV_rfr = RandomizedSearchCV(estimator=rfr, param_distributions=param_grid, cv=3)\n",
    "CV_rfr.fit(X_train, y_train)\n",
    "\n",
    "print('Best Params: ', CV_rfr.best_params_)\n",
    "bp = CV_rfr.best_params_ # best parameters\n",
    "\n",
    "rfr = RandomForestRegressor(\n",
    "    n_estimators = bp['n_estimators'], \n",
    "    max_features=bp['max_features'],\n",
    "    min_samples_leaf=bp['min_samples_leaf'], \n",
    "    max_depth=bp['max_depth'])\n",
    "\n",
    "rfr.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "y_pred_train = rfr.predict(X_train)\n",
    "rmseTrain = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "print(\"Train RMSE: {}\".format(rmseTrain))\n",
    "\n",
    "y_pred = rfr.predict(X_test)\n",
    "rmseTest = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Test RMSE: {}\\n\".format(rmseTest))\n",
    "\n",
    "print('Ending at: ', datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting at:  2018-03-30 07:10:21.667214\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter max_iter for estimator RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n           max_features='auto', max_leaf_nodes=None,\n           min_impurity_decrease=0.0, min_impurity_split=None,\n           min_samples_leaf=1, min_samples_split=2,\n           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n           oob_score=True, random_state=0, verbose=0, warm_start=False). Check the list of available parameters with `estimator.get_params().keys()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-486c92c73443>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mrfr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moob_score\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mCV_rfr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrfr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_distributions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mCV_rfr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Parameters and Score for data set:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0mtrain_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mset_params\u001b[0;34m(self, **params)\u001b[0m\n\u001b[1;32m    272\u001b[0m                                  \u001b[0;34m'Check the list of available parameters '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m                                  \u001b[0;34m'with `estimator.get_params().keys()`.'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m                                  (key, self))\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdelim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid parameter max_iter for estimator RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n           max_features='auto', max_leaf_nodes=None,\n           min_impurity_decrease=0.0, min_impurity_split=None,\n           min_samples_leaf=1, min_samples_split=2,\n           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n           oob_score=True, random_state=0, verbose=0, warm_start=False). Check the list of available parameters with `estimator.get_params().keys()`."
     ]
    }
   ],
   "source": [
    "# Random search on random forest regression for each data drame\n",
    "# Saves dataframe and associated best parameters in dictionary \n",
    "# for data frame with lowest test RMSE\n",
    "\n",
    "print('Starting random search on RFR at: ', datetime.datetime.now())\n",
    "\n",
    "param_grid = { \n",
    "              \"n_estimators\": np.arange(200, 500, 50),\n",
    "              \"max_features\" : ['auto'],\n",
    "              \"min_samples_leaf\": np.arange(10,30,5),\n",
    "              'max_depth' : np.arange(20, 60, 10)\n",
    "}\n",
    "\n",
    "i = 1\n",
    "\n",
    "for v in zip(xs, ys):\n",
    "    \n",
    "    x_, y_ = v\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_, y_, test_size = .3, random_state=42)\n",
    "    \n",
    "    rfr = RandomForestRegressor(n_jobs=-1, oob_score= True, random_state = 0)\n",
    "    \n",
    "    CV_rfr = RandomizedSearchCV(estimator=rfr, param_distributions=param_grid, cv=3)\n",
    "    \n",
    "    CV_rfr.fit(X_train, y_train)\n",
    "    \n",
    "    print('Parameters and Score for data set:', i)\n",
    "    print('Best Params: ', CV_rfr.best_params_)\n",
    "    bp = CV_rfr.best_params_ \n",
    "\n",
    "    rfr = RandomForestRegressor(\n",
    "    n_estimators = bp['n_estimators'], \n",
    "    max_features=bp['max_features'],\n",
    "    min_samples_leaf=bp['min_samples_leaf'], \n",
    "    max_depth=bp['max_depth'])\n",
    "\n",
    "    rfr.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_train = rfr.predict(X_train)\n",
    "    rmseTrain = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "    print(\"Train RMSE: {}\".format(rmseTrain))\n",
    "\n",
    "    y_pred = rfr.predict(X_test)\n",
    "    rmseTest = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    print(\"Test RMSE: {}\\n\".format(rmseTest))\n",
    "    \n",
    "    rmse = rmseTest\n",
    "    \n",
    "    if(i == 1):\n",
    "        best_rmse = rmse\n",
    "        best_df = i\n",
    "        bps = bp\n",
    "    \n",
    "    if (rmse < best_rmse):\n",
    "        best_rmse = rmse\n",
    "        best_df = i\n",
    "        bps = bp\n",
    "    \n",
    "    i +=1\n",
    "    \n",
    "print('Ending random search for RFR at: ', datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bestx = xs[2]\n",
    "bestxT = testDfs[2]\n",
    "besty = ys[2]\n",
    "bp = {'n_estimators': 450, 'min_samples_leaf': 25, 'max_features': 'auto', 'max_depth': 40}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sets best dataframe and best set of parameters for data frame with lowests RMSE\n",
    "bestx = xs[best_df-1]\n",
    "bestxT = testDfs[best_df-1\n",
    "besty = ys[best_df-1]\n",
    "bp = bps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting grid search on RFR at:  2018-04-10 12:15:35.722759\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-791199ff4f43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mCV_rfr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrfr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mCV_rfr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mbp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCV_rfr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    943\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtest\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \"\"\"\n\u001b[0;32m--> 945\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[1;32m    562\u001b[0m                                   \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m--> 564\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m           for train, test in cv_iter)\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    324\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 326\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    766\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    680\u001b[0m                 \u001b[0;31m# check if timeout supported in backend future implementation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m'timeout'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgetfullargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Gridsearch on RFR for best dataframe\n",
    "print('Starting grid search on RFR at: ', datetime.datetime.now())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(bestx, besty, test_size = .3, random_state=42)\n",
    "\n",
    "rfr = RandomForestRegressor(n_jobs=-1, oob_score= True, random_state = 0) \n",
    "\n",
    "param_grid = { \n",
    "              \"n_estimators\": np.arange(200, 500, 50),\n",
    "              \"max_features\" : ['auto'],\n",
    "              \"min_samples_leaf\": np.arange(10,30,5),\n",
    "              'max_depth' : np.arange(20, 60, 10)\n",
    "}\n",
    "\n",
    "CV_rfr = GridSearchCV(estimator=rfr, param_grid=param_grid, cv= 3)\n",
    "\n",
    "CV_rfr.fit(X_train, y_train)\n",
    "\n",
    "bp = CV_rfr.best_params_\n",
    "\n",
    "print (CV_rfr.best_params_)\n",
    "print('Ending grid search on RFR at: ', datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature trimming with Random Forest\n",
    "print('Starting RFR at: ', datetime.datetime.now())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(bestx, besty, test_size = .3, random_state=42)\n",
    "\n",
    "rfr = RandomForestRegressor(n_jobs=-1, oob_score= True, random_state = 0, \n",
    "                n_estimators = bp['n_estimators'], \n",
    "                max_features = bp['max_features'], \n",
    "                min_samples_leaf=bp['min_samples_leaf'], \n",
    "                max_depth = bp['max_depth'])\n",
    "    \n",
    "rfr.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = rfr.predict(X_train)\n",
    "rmseTrain = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "print(\"Train RMSE: {}\".format(rmseTrain))\n",
    "\n",
    "y_pred = rfr.predict(X_test)\n",
    "rmseTest = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Test RMSE: {}\\n\".format(rmseTest))\n",
    "\n",
    "print('Ending RFR at: ', datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creates a dataframe of feature importances\n",
    "feature_importance = list(rfr.feature_importances_)\n",
    "features = list(bestx.columns)\n",
    "\n",
    "\n",
    "feature_importances = pd.DataFrame({'Feature': features, 'Importance': feature_importance})\n",
    "\n",
    "print('Feature importance determined from random forest')\n",
    "print(feature_importances.sort_values('importance', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Iterates through subsets of features with increasingly more important \n",
    "# subsets of features and calculates the train and test RMSE during each iteration\n",
    "\n",
    "print('Start random forest feature trimming at: ', datetime.datetime.now())\n",
    "\n",
    "for i in np.arange(.0008, .0024, .0002):\n",
    "    threshold = i\n",
    "    new = features[feature_importance > threshold].tolist()\n",
    "    newdf = bestx[new]\n",
    "    print(new)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(newdf, besty, test_size = .1, random_state=42)\n",
    "    \n",
    "    rfr.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_train = rfr.predict(X_train)\n",
    "    rmseTrain = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "    print(\"Train RMSE: {}\".format(rmseTrain))\n",
    "\n",
    "    y_pred = rfr.predict(X_test)\n",
    "    rmseTest = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    print(\"Test RMSE: {}\\n\".format(rmseTest))\n",
    "    \n",
    "    rmse = rmseTest\n",
    "    \n",
    "    if(i == .0008):\n",
    "        best_rmse = rmse\n",
    "        best_df = newdf\n",
    "        \n",
    "    \n",
    "    if (rmse < best_rmse):\n",
    "        best_rmse = rmse\n",
    "        best_df = newdf\n",
    "      \n",
    "    \n",
    "    i +=1\n",
    "    \n",
    "    \n",
    "print('Ending RFR trimming at: ', datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I was unable to improve the RMSE for random forest regressor from manually trimming "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Below produces a submission file for the RFR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sets RFR with optimized paramters from gridsearch and fits model\n",
    "rfr = RandomForestRegressor(n_jobs=-1, oob_score= True, random_state = 0, \n",
    "                n_estimators = bp['n_estimators'], \n",
    "                max_features = bp['max_features'], \n",
    "                min_samples_leaf=bp['min_samples_leaf'], \n",
    "                max_depth = bp['max_depth'])\n",
    "\n",
    "rfr.fit(bestx, besty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Produces submission file\n",
    "y_pred_submission = rfr.predict(bestxT)\n",
    "y_pred_DF = pd.DataFrame(y_pred_submission)\n",
    "submission = pd.concat([UP, y_pred_DF], axis=1)\n",
    "submission = submission1.rename(columns={0: 'Purchase'})\n",
    "submission.to_csv('Output/rfr.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grandient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start GBR at:  2018-04-10 20:29:47.846803\n",
      "Score for data set: 1\n",
      "Train RMSE: 4738.400826743601\n",
      "Test RMSE: 4758.865574375839\n",
      "\n",
      "Score for data set: 2\n",
      "Train RMSE: 4738.400826743601\n",
      "Test RMSE: 4758.863257942176\n",
      "\n",
      "Score for data set: 3\n",
      "Train RMSE: 4738.910670356826\n",
      "Test RMSE: 4759.622906381364\n",
      "\n",
      "Score for data set: 4\n",
      "Train RMSE: 4738.910670356826\n",
      "Test RMSE: 4759.623073113583\n",
      "\n",
      "Ending GBR at:  2018-04-10 20:36:37.033911\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Regression\n",
    "print('Start GBR at: ', datetime.datetime.now())\n",
    "\n",
    "i = 1\n",
    "for v in zip(xs, ys):\n",
    "    x_, y_ = v\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_, y_, test_size = .3, random_state=42)\n",
    "    \n",
    "    gbr = GradientBoostingRegressor(random_state =0)\n",
    "\n",
    "    print('Score for data set:', i)\n",
    "\n",
    "    gbr.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_train = gbr.predict(X_train)\n",
    "    rmseTrain = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "    print(\"Train RMSE: {}\".format(rmseTrain))\n",
    "\n",
    "    y_pred = gbr.predict(X_test)\n",
    "    rmseTest = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    print(\"Test RMSE: {}\\n\".format(rmseTest))\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "print('Ending GBR at: ', datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Script to run Randomsearch on each data frame for Gradient Boosting model and then set \n",
    "# best paramters based on the randomsearch and rerun for that model \n",
    "print('Start random search on GBR at: ', datetime.datetime.now())\n",
    "\n",
    "param_grid = {'learning_rate':  [.01, .05, 0.15, 0.3, 0.5],\n",
    "              'max_depth': [8, 9, 10, 11, 12],\n",
    "              'min_samples_leaf': [ 15, 18, 21, 24],\n",
    "              'max_features': np.arange(25, 50, 5)\n",
    "              }  \n",
    "\n",
    "i = 1\n",
    "\n",
    "for v in zip(xs, ys):\n",
    "    x_, y_ = v\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_, y_, test_size = .3, random_state=42)\n",
    "    gbr = GradientBoostingRegressor(random_state =0)\n",
    "    CV_gbr = RandomizedSearchCV(estimator=gbr, param_distributions=param_grid, cv=3)\n",
    "    CV_gbr.fit(X_train, y_train)\n",
    "    print('Best Params and Score for data set:', i, '\\n')\n",
    "\n",
    "    print('Best Params: ', CV_rfr.best_params_ ,'\\n')\n",
    "    bp = CV_gbr.best_params_ # best parameters\n",
    "\n",
    "    gbr = GradientBoostingRegressor(learning_rate = bp['learning_rate'], \n",
    "    max_features=bp['max_features'],\n",
    "    min_samples_leaf=bp['min_samples_leaf'], \n",
    "    max_depth=bp['max_depth'])\n",
    "\n",
    "    gbr.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_train = gbr.predict(X_train)\n",
    "    rmseTrain = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "    print(\"Train RMSE: {}\".format(rmseTrain))\n",
    "\n",
    "    y_pred = gbr.predict(X_test)\n",
    "    rmseTest = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    print(\"Test RMSE: {}\\n\".format(rmseTest))\n",
    "    \n",
    "    rmse = rmseTest\n",
    "    \n",
    "    if(i == 1):\n",
    "        best_rmse = rmse\n",
    "        best_df = i\n",
    "        bps = bp\n",
    "    \n",
    "    if (rmse < best_rmse):\n",
    "        best_rmse = rmse\n",
    "        best_df = i\n",
    "        bps = bp\n",
    "    \n",
    "    i +=1\n",
    "    \n",
    "print('Ending random search for GBR at: ', datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sets best dataframe and best set of parameters for data frame with lowests RMSE\n",
    "bestx = xs[best_df-1]\n",
    "bestxT = testDfs[best_df-1\n",
    "besty = ys[best_df-1]\n",
    "bp = bps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Grid search for GBR\n",
    "print('Start grid search on GBR at: ', datetime.datetime.now())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(bestx, besty, test_size = .3, random_state=42)\n",
    "gbr = gbr(n_jobs=-1, oob_score= True, random_state = 0) \n",
    "\n",
    "\n",
    "param_grid = {'learning_rate':  [.01, .05, 0.15, 0.3, 0.5],\n",
    "              'max_depth': [8, 9, 10, 11, 12],\n",
    "              'min_samples_leaf': [ 15, 18, 21, 24],\n",
    "              'max_features': np.arange(25, 50, 5)\n",
    "              }  \n",
    "print('Starting at: ', datetime.datetime.now())\n",
    "\n",
    "CV_gbr = GridSearchCV(estimator=gbr, param_grid=param_grid, cv= 3)\n",
    "CV_gbr.fit(X_train, y_train)\n",
    "bps = CV_rfc.best_params_\n",
    "print (CV_rfc.best_params_)\n",
    "\n",
    "print('Ending grid search on GBR at: ', datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sets gridsearch optimized parameters on GBR model\n",
    "gbr = GradientBoostingRegressor(learning_rate = bps['learning_rate'], \n",
    "    max_features=bps['max_features'],\n",
    "    min_samples_leaf=bps['min_samples_leaf'], \n",
    "    max_depth=bps['max_depth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Produces submission file for GBR\n",
    "y_pred_submission = gbr.predict(bestxT)\n",
    "y_pred_DF = pd.DataFrame(y_pred_submission)\n",
    "submission = pd.concat([UP, y_pred_DF], axis=1)\n",
    "submission = submission1.rename(columns={0: 'Purchase'})\n",
    "submission.to_csv('Output/gbr.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting MLPR at:  2018-04-10 20:13:05.953755\n",
      "Score for data set: 1\n",
      "Train RMSE: 4750.672090536564\n",
      "Test RMSE: 4766.517437297264\n",
      "\n",
      "Score for data set: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 4735.771389125665\n",
      "Test RMSE: 4759.774107837551\n",
      "\n",
      "Score for data set: 3\n",
      "Train RMSE: 4749.913677911979\n",
      "Test RMSE: 4765.9690408197675\n",
      "\n",
      "Score for data set: 4\n",
      "Train RMSE: 4738.549853044244\n",
      "Test RMSE: 4761.111929935567\n",
      "\n",
      "Ending MLPR at:  2018-04-10 20:29:47.786271\n"
     ]
    }
   ],
   "source": [
    "# Multi-layer perceptron regressor\n",
    "print('Starting MLPR at: ', datetime.datetime.now())\n",
    "\n",
    "i = 1\n",
    "for v in zip(xs, ys):\n",
    "    x_, y_ = v\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_, y_, test_size = .3, random_state=42)\n",
    "    \n",
    "    mlp = MLPRegressor(random_state =0)\n",
    "\n",
    "    print('Score for data set:', i)\n",
    "    \n",
    "    mlp.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_train = mlp.predict(X_train)\n",
    "    rmseTrain = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "    print(\"Train RMSE: {}\".format(rmseTrain))\n",
    "\n",
    "    y_pred = mlp.predict(X_test)\n",
    "    rmseTest = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    print(\"Test RMSE: {}\\n\".format(rmseTest))\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "print('Ending MLPR at: ', datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random search on MLPR\n",
    "print('Starting random search for MLPR at: ', datetime.datetime.now())\n",
    "\n",
    "param_grid = { \n",
    "    \"hidden_layer_sizes\" : [2, 3],\n",
    "    \"alpha\" : [.0001, .001, .01],\n",
    "    \"batch_size\" : [1, 10, 50, 100, 250],\n",
    "    \"max_iter\"  : np.arange(1250, 2250, 250)\n",
    "            }\n",
    "\n",
    "i = 1\n",
    "for v in zip(xs, ys):\n",
    "    x_, y_ = v\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_, y_, test_size = .3, random_state=42)\n",
    "\n",
    "    mlp = MLPRegressor(random_state = 0) \n",
    "\n",
    "    rs_mlp = RandomizedSearchCV(estimator=mlp, param_distributions=param_grid, cv= 3)\n",
    "    rs_mlp.fit(X_train, y_train)\n",
    "    print (rs_mlp.best_params_)\n",
    "    bp = rs_mlp.best_params_\n",
    "\n",
    "    print('Starting at: ', datetime.datetime.now())\n",
    "\n",
    "    mlp = MLPRegressor(hidden_layer_sizes = bp['hidden_layer_sizes'], \n",
    "    alpha=bp['alpha'],\n",
    "    batch_size=bp['batch_size'], \n",
    "    max_iter=bp['max_iter'])\n",
    "\n",
    "    mlp.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_train = mlp.predict(X_train)\n",
    "    rmseTrain = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "    print(\"Train RMSE: {}\".format(rmseTrain))\n",
    "\n",
    "    y_pred = mlp.predict(X_test)\n",
    "    rmseTest = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    print(\"Test RMSE: {}\\n\".format(rmseTest))\n",
    "    \n",
    "    rmse = rmseTest\n",
    "    \n",
    "    if(i == 1):\n",
    "        best_rmse = rmse\n",
    "        best_df = i\n",
    "        bps = bp\n",
    "    \n",
    "    if (rmse < best_rmse):\n",
    "        best_rmse = rmse\n",
    "        best_df = i\n",
    "        bps = bp\n",
    "    \n",
    "    i +=1\n",
    "\n",
    "print('Ending at: ', datetime.datetime.now())\n",
    "print('Ending random search on MLPR at: ', datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sets best dataframe and best set of parameters for data frame with lowests RMSE\n",
    "bestx = xs[best_df-1]\n",
    "bestxT = testDfs[best_df-1\n",
    "besty = ys[best_df-1]\n",
    "bp = bps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Gridsearch on MLPR\n",
    "print('Starting gridsearch for MLPR at: ', datetime.datetime.now())\n",
    "\n",
    "param_grid = { \n",
    "    \"hidden_layer_sizes\" : [2, 3],\n",
    "    \"alpha\" : [.0001, .001, .01],\n",
    "    \"batch_size\" : [1, 10, 50, 100, 250],\n",
    "    \"max_iter\"  : np.arange(1250, 2250, 250)\n",
    "            }\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(xNoNbNorm, yNoNbNorm, test_size = .3, random_state=42)\n",
    "\n",
    "mlp = MLPRegressor(random_state = 0) \n",
    "\n",
    "rs_mlp = GridSearchCV(estimator=mlp, param_grid=param_grid, cv= 3)\n",
    "\n",
    "rs_mlp.fit(X_train, y_train)\n",
    "\n",
    "print('Best Params: ', rs_mlp.best_params_)\n",
    "bp = rs_mlp.best_params_ # best parameters\n",
    "\n",
    "mlp = MLPRegressor(hidden_layer_sizes = bp['hidden_layer_sizes'], \n",
    "alpha=bp['alpha'],\n",
    "batch_size=bp['batch_size'], \n",
    "max_iter=bp['max_iter'])\n",
    "\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = mlp.predict(X_train)\n",
    "rmseTrain = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "print(\"Train RMSE: {}\".format(rmseTrain))\n",
    "\n",
    "y_pred = mlp.predict(X_test)\n",
    "rmseTest = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Test RMSE: {}\\n\".format(rmseTest))\n",
    "\n",
    "print('Ending gridsearch for MLPR at: ', datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sets best parameters from grid search on MLPR model\n",
    "mlp = MLPRegressor(hidden_layer_sizes = bps['hidden_layer_sizes'], \n",
    "    alpha=bps['alpha'],\n",
    "    batch_size=bps['batch_size'], \n",
    "    max_iter=bps['max_iter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Produces MLPR submission\n",
    "y_pred_submission = mlp.predict(bestxT)\n",
    "y_pred_DF = pd.DataFrame(y_pred_submission)\n",
    "submission = pd.concat([UP, y_pred_DF], axis=1)\n",
    "submission = submission1.rename(columns={0: 'Purchase'})\n",
    "submission.to_csv('Output/mlpr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
